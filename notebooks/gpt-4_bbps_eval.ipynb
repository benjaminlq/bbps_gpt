{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = os.path.dirname(os.getcwd())\n",
    "DATA_DIR = os.path.join(MAIN_DIR, \"data\")\n",
    "ARTIFACT_DIR = os.path.join(MAIN_DIR, \"artifacts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(score):\n",
    "    if score == 0 or score == 1:\n",
    "        return 0\n",
    "    elif score == 2 or score == 3:\n",
    "        return 1\n",
    "    elif score == -1:\n",
    "        return -1\n",
    "    else:\n",
    "        ValueError(\"Invalid Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_score_folder = \"bbps-0-1\"\n",
    "data_folder = os.path.join(DATA_DIR, \"hyper-kvasir\")\n",
    "\n",
    "with open(os.path.join(data_folder, \"testcases.txt\"), 'r') as fp:\n",
    "    data = fp.read()\n",
    "    all_file_paths = data.split(\"\\n\") \n",
    "\n",
    "gt_scores = [0 if (path.split(\"/\")[-2] == low_score_folder) else 1 for path in all_file_paths]\n",
    "filenames = [path.split(\"/\")[-1] for path in all_file_paths]\n",
    "\n",
    "assert len(gt_scores) == len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>fs_text_raw_answer</th>\n",
       "      <th>gpt_score</th>\n",
       "      <th>gt_score</th>\n",
       "      <th>gt_class</th>\n",
       "      <th>gpt_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f69bfb02-30c2-477c-905f-4c219dba30b1.jpg</td>\n",
       "      <td>Based on the image provided, the bowel prepara...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21ab075e-3ac3-4e8f-a455-6ca78dc5a248.jpg</td>\n",
       "      <td>Based on the image provided, the mucosa of the...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>be4dff9c-3f5d-40c2-8628-ee83c597b653.jpg</td>\n",
       "      <td>Based on the image provided, the mucosa of the...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a70e990c-9ae8-44bc-8e04-92071ee88039.jpg</td>\n",
       "      <td>Based on the image provided, the mucosa of the...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c6aae080-89f2-46e7-8fa9-266d57309b9c.jpg</td>\n",
       "      <td>The image shows a colon segment with clear vis...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   filename  \\\n",
       "0  f69bfb02-30c2-477c-905f-4c219dba30b1.jpg   \n",
       "1  21ab075e-3ac3-4e8f-a455-6ca78dc5a248.jpg   \n",
       "2  be4dff9c-3f5d-40c2-8628-ee83c597b653.jpg   \n",
       "3  a70e990c-9ae8-44bc-8e04-92071ee88039.jpg   \n",
       "4  c6aae080-89f2-46e7-8fa9-266d57309b9c.jpg   \n",
       "\n",
       "                                  fs_text_raw_answer  gpt_score  gt_score  \\\n",
       "0  Based on the image provided, the bowel prepara...        1.0         1   \n",
       "1  Based on the image provided, the mucosa of the...        3.0         3   \n",
       "2  Based on the image provided, the mucosa of the...        2.0         1   \n",
       "3  Based on the image provided, the mucosa of the...        3.0         3   \n",
       "4  The image shows a colon segment with clear vis...        3.0         3   \n",
       "\n",
       "   gt_class  gpt_class  \n",
       "0         0          0  \n",
       "1         1          1  \n",
       "2         0          1  \n",
       "3         1          1  \n",
       "4         1          1  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.read_csv(\n",
    "    os.path.join(ARTIFACT_DIR, \"hyper-kvasir\", \"run_1\", \"result_0-1794.csv\"),\n",
    "    usecols = [\"filename\", \"fs_text_raw_answer\", \"fs_text_score\"]\n",
    ")\n",
    "\n",
    "result_df = result_df.rename(columns = {\"fs_text_score\": \"gpt_score\"})\n",
    "\n",
    "GT_DIR = os.path.join(DATA_DIR, \"hyper-kvasir\", \"ground_truths\")\n",
    "\n",
    "gt_dict = {}\n",
    "\n",
    "for gt_score in range(4):\n",
    "    img_folder = \"BBPS \" + str(gt_score)\n",
    "    img_files = os.listdir(os.path.join(GT_DIR, img_folder))\n",
    "    for img_file in img_files:\n",
    "        gt_dict[img_file] = gt_score\n",
    "\n",
    "result_df[\"gpt_score\"] = result_df[\"gpt_score\"].fillna(-1)\n",
    "result_df[\"gt_score\"] = [gt_dict[file] for file in result_df[\"filename\"]]\n",
    "\n",
    "result_df[\"gt_class\"] = result_df[\"gt_score\"].apply(lambda x: classify(x))\n",
    "result_df[\"gpt_class\"] = result_df[\"gpt_score\"].apply(lambda x: classify(x))\n",
    "\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, accuracy_score, recall_score, classification_report, cohen_kappa_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score (0, 1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0    0.00000   0.00000   0.00000         0\n",
      "         0.0    0.61386   0.49600   0.54867       125\n",
      "         1.0    0.82692   0.42744   0.56356       503\n",
      "         2.0    0.38527   0.73118   0.50464       186\n",
      "         3.0    0.87996   0.95000   0.91364       980\n",
      "\n",
      "    accuracy                        0.74916      1794\n",
      "   macro avg    0.54120   0.52092   0.50610      1794\n",
      "weighted avg    0.79526   0.74916   0.74765      1794\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/QUAN/Desktop/bbps_gpt/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/c/Users/QUAN/Desktop/bbps_gpt/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/c/Users/QUAN/Desktop/bbps_gpt/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "preds = result_df[\"gpt_score\"]\n",
    "labels = result_df[\"gt_score\"]\n",
    "\n",
    "print(classification_report(labels, preds, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_na_preds = result_df[result_df[\"gpt_score\"] != -1][\"gpt_score\"]\n",
    "no_na_labels = result_df[result_df[\"gt_score\"] != -1][\"gpt_score\"]\n",
    "\n",
    "print(classification_report(labels, preds, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6189504360186617\n"
     ]
    }
   ],
   "source": [
    "preds = result_df[\"gpt_class\"]\n",
    "labels = result_df[\"gt_class\"]\n",
    "\n",
    "print(cohen_kappa_score(labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gt_score</th>\n",
       "      <th>gpt_score</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gt_score  gpt_score  count\n",
       "0          0        0.0     62\n",
       "1          0        1.0     41\n",
       "2          0        3.0     10\n",
       "3          0       -1.0      7\n",
       "4          0        2.0      5\n",
       "5          1        1.0    215\n",
       "6          1        2.0    177\n",
       "7          1        3.0     68\n",
       "8          1        0.0     39\n",
       "9          1       -1.0      4\n",
       "10         2        2.0    136\n",
       "11         2        3.0     49\n",
       "12         2        1.0      1\n",
       "13         3        3.0    931\n",
       "14         3        2.0     35\n",
       "15         3       -1.0     11\n",
       "16         3        1.0      3"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.groupby(\"gt_score\")[\"gpt_score\"].value_counts().reset_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
